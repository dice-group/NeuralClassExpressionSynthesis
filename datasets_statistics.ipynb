{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "corresponding-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from owlapy.render import DLSyntaxObjectRenderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "elementary-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "altered-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(kb: str):\n",
    "    renderer = DLSyntaxObjectRenderer()\n",
    "    KB = KnowledgeBase(path=f'datasets/{kb}/{kb}.owl')\n",
    "    atomic_concepts = [renderer.render(c) for c in KB.ontology().classes_in_signature()]\n",
    "    role_names = [rel.get_iri().get_remainder() for rel in KB.ontology().object_properties_in_signature()]\n",
    "    vocab = atomic_concepts + role_names + ['⊔', '⊓', '∃', '∀', '¬', '⊤', '⊥', '.', ' ', '(', ')']\n",
    "    vocab_card = len(vocab)\n",
    "    with open(f'datasets/{kb}/Train_data/Data.json') as lp:\n",
    "        data = json.load(lp)\n",
    "    with open(f'datasets/{kb}/Test_data/Data.json') as lp:\n",
    "        data_test = json.load(lp)\n",
    "    train_card = len(data)\n",
    "    lp_card = len(data_test)\n",
    "    print(f\"|Vocab|: {vocab_card}, |Train|: {train_card}, |LP|: {lp_card}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "minimal-feeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 157, |Train|: 10982, |LP|: 111\n"
     ]
    }
   ],
   "source": [
    "statistics('carcinogenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "south-python",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 102, |Train|: 5333, |LP|: 54\n"
     ]
    }
   ],
   "source": [
    "statistics('mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "streaming-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 88, |Train|: 3896, |LP|: 40\n"
     ]
    }
   ],
   "source": [
    "statistics('semantic_bible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "lesbian-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 215, |Train|: 18243, |LP|: 175\n"
     ]
    }
   ],
   "source": [
    "statistics('vicodi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-essex",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
