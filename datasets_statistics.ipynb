{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tribal-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from owlapy.render import DLSyntaxObjectRenderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confused-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "happy-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(kb: str):\n",
    "    renderer = DLSyntaxObjectRenderer()\n",
    "    KB = KnowledgeBase(path=f'datasets/{kb}/{kb}.owl')\n",
    "    atomic_concepts = [renderer.render(c) for c in KB.ontology().classes_in_signature()]\n",
    "    role_names = [rel.get_iri().get_remainder() for rel in KB.ontology().object_properties_in_signature()]\n",
    "    vocab = atomic_concepts + role_names + ['⊔', '⊓', '∃', '∀', '¬', '⊤', '⊥', '.', ' ', '(', ')']\n",
    "    vocab_card = len(vocab)\n",
    "    with open(f'datasets/{kb}/Train_data/Data.json') as lp:\n",
    "        data = json.load(lp)\n",
    "    with open(f'datasets/{kb}/Test_data/Data.json') as lp:\n",
    "        data_test = json.load(lp)\n",
    "    train_card = len(data)\n",
    "    lp_card = len(data_test)\n",
    "    print(f\"|Vocab|: {vocab_card}, |Train|: {train_card}, |LP|: {lp_card}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "automotive-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 157, |Train|: 9662, |LP|: 98\n"
     ]
    }
   ],
   "source": [
    "statistics('carcinogenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "exceptional-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 102, |Train|: 2138, |LP|: 22\n"
     ]
    }
   ],
   "source": [
    "statistics('mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "endangered-outline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 88, |Train|: 2479, |LP|: 26\n"
     ]
    }
   ],
   "source": [
    "statistics('semantic_bible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dangerous-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Vocab|: 215, |Train|: 15533, |LP|: 157\n"
     ]
    }
   ],
   "source": [
    "statistics('vicodi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spatial-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlapy.parser import DLSyntaxParser\n",
    "from utils.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "super-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_metrics(kb):\n",
    "    KB = KnowledgeBase(path=f'datasets/{kb}/{kb}.owl')\n",
    "    namespace = KB.ontology()._onto.base_iri\n",
    "    if kb == 'family-benchmark':\n",
    "        namespace = 'http://www.benchmark.org/family#'\n",
    "    if kb == 'vicodi':\n",
    "        namespace = 'http://vicodi.org/ontology#'\n",
    "    print()\n",
    "    evaluator = Evaluator(KB)\n",
    "    dl_parser = DLSyntaxParser(namespace = namespace)\n",
    "    All_individuals = set(KB.individuals())\n",
    "    for model in ['eltl', 'celoe']:\n",
    "        print(f'Model: {model.upper()}\\n')\n",
    "        with open(f'datasets/{kb}/Results/concept_learning_results_{model}.json') as file:\n",
    "            results = json.load(file)\n",
    "        new_results = {'F-measure': [], 'Accuracy': [], 'Runtime': [], 'Prediction': [], 'Length': [], 'Learned Concept': []}\n",
    "        for key in results:\n",
    "            if key not in ['F-measure', 'Accuracy']:\n",
    "                new_results[key] = results[key]\n",
    "        prediction = results['Prediction']\n",
    "        for pred, target in zip(prediction, results['Learned Concept']):\n",
    "            target_expression = dl_parser.parse_expression(target)\n",
    "            positive_examples = {ind.get_iri().as_str().split(\"/\")[-1] for ind in KB.individuals(target_expression)}\n",
    "            negative_examples = All_individuals-positive_examples\n",
    "            Pred = dl_parser.parse_expression(pred)\n",
    "            acc, f1 = evaluator.evaluate(Pred, positive_examples, negative_examples)\n",
    "            new_results['F-measure'].append(f1)\n",
    "            new_results['Accuracy'].append(acc)\n",
    "            print(f'F1: {f1}, Acc: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-bracelet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
