{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpha-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_metric(metric):\n",
    "    if metric == 'F-measure':\n",
    "        return 'f1'\n",
    "    if metric == 'Accuracy':\n",
    "        return 'acc'\n",
    "    if metric == 'Runtime':\n",
    "        return 'time'\n",
    "    raise ValueError('Unknown metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "casual-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(metric):\n",
    "    Res = {metric: {'Carcinogenesis': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''},\n",
    "                   'Mutagenesis': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''},\n",
    "                    'Semantic Bible': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''},\n",
    "                    'Vicodi': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''}\n",
    "                   }}\n",
    "    for kb in ['carcinogenesis', 'mutagenesis', 'semantic_bible', 'vicodi']:\n",
    "        for model in ['celoe', 'eltl', 'ecii', 'evolearner', 'NCES', 'NCES_Ensemble']:\n",
    "            if model not in ['NCES', 'NCES_Ensemble']:\n",
    "                with open(f'datasets/{kb}/Results/concept_learning_avg_results__{model}.json') as file:\n",
    "                    results = json.load(file)\n",
    "                rename_model = model.upper() if model != 'evolearner' else 'EvoLearner'\n",
    "                if model == 'ecii':\n",
    "                    if metric != 'Accuracy':\n",
    "                        Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] =\\\n",
    "                    str(round(100*results[metric]['mean'],2))+'$\\pm$'+str(round(100*results[metric]['std'],2))\n",
    "                    else:\n",
    "                        Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] =\\\n",
    "                    '-'+'$\\pm$'+'-'\n",
    "                else:\n",
    "                    Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] =\\\n",
    "                    str(round(results[metric]['mean'],2))+'$\\pm$'+str(round(results[metric]['std'],2))\n",
    "            elif model == 'NCES':\n",
    "                with open(f'datasets/{kb}/Results/{model}.json') as file:\n",
    "                    results = json.load(file)\n",
    "                new_metric = rename_metric(metric)\n",
    "                for m in results: \n",
    "                    rename_model = 'NCES$_'+'{\\\\text{'+m+'}}$' if m != 'SetTransformer' else 'NCES$_'+'{\\\\text{'+'ST'+'}}$'\n",
    "                    Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] =\\\n",
    "                    str(round(results[m][new_metric]['mean'][0],2))+'$\\pm$'+str(round(results[m][new_metric]['std'][0],2))\n",
    "            elif model == 'NCES_Ensemble':\n",
    "                with open(f'datasets/{kb}/Results/{model}.json') as file:\n",
    "                    results = json.load(file)\n",
    "                new_metric = rename_metric(metric)\n",
    "                for m in results:\n",
    "                    rename_model = 'NCES$_'+'{\\\\text{'+m+'}}$' if not 'SetTransformer' in m \\\n",
    "                    else 'NCES$_'+'{\\\\text{'+m.replace('SetTransformer', 'ST')+'}}$'\n",
    "                    Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] =\\\n",
    "                    str(round(results[m][new_metric]['mean'][0],2))+'$\\pm$'+str(round(results[m][new_metric]['std'][0],2))\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "casual-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_shuffle(metric):\n",
    "    Res = {metric: {'Carcinogenesis': {'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': ''},\n",
    "                   'Mutagenesis': {'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': ''},\n",
    "                    'Semantic Bible': {'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': ''},\n",
    "                    'Vicodi': {'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': ''}\n",
    "                   }}\n",
    "    for kb in ['carcinogenesis', 'mutagenesis', 'semantic_bible', 'vicodi']:\n",
    "        with open(f'datasets/{kb}/Results/NCES_Shuffle.json') as file:\n",
    "            results = json.load(file)\n",
    "        with open(f'datasets/{kb}/Results/NCES.json') as file:\n",
    "            results_initial = json.load(file)\n",
    "        new_metric = rename_metric(metric)\n",
    "        difference_results = {m: {new_metric: results[m][new_metric]['mean'][0]-results_initial[m][new_metric]['mean'][0]} for m in results}\n",
    "        \n",
    "        for m in difference_results: \n",
    "            rename_model = 'NCES$_'+'{\\\\text{'+m+'}}$' if m != 'SetTransformer' else 'NCES$_'+'{\\\\text{'+'ST'+'}}$'\n",
    "            Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] =\\\n",
    "            str(round(difference_results[m][new_metric],2))\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "correct-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "Res1 = get_results_shuffle('F-measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "standing-growth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F-measure': {'Carcinogenesis': {'NCES$_{\\\\text{LSTM}}$': '-2.14',\n",
       "   'NCES$_{\\\\text{GRU}}$': '2.07',\n",
       "   'NCES$_{\\\\text{ST}}$': '0.0'},\n",
       "  'Mutagenesis': {'NCES$_{\\\\text{LSTM}}$': '1.96',\n",
       "   'NCES$_{\\\\text{GRU}}$': '19.06',\n",
       "   'NCES$_{\\\\text{ST}}$': '0.0'},\n",
       "  'Semantic Bible': {'NCES$_{\\\\text{LSTM}}$': '-10.74',\n",
       "   'NCES$_{\\\\text{GRU}}$': '-9.78',\n",
       "   'NCES$_{\\\\text{ST}}$': '0.0'},\n",
       "  'Vicodi': {'NCES$_{\\\\text{LSTM}}$': '-0.49',\n",
       "   'NCES$_{\\\\text{GRU}}$': '2.71',\n",
       "   'NCES$_{\\\\text{ST}}$': '0.0'}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afraid-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(metric):\n",
    "    data = get_results(metric)\n",
    "    with open(f'{metric}.txt', 'w') as file:\n",
    "        for key in data:\n",
    "            file.write(\"\\\\begin{tabular}{@{}lccccccc@{}}\\n\")\n",
    "            file.write(\"\\t\\t\\\\toprule\\n\")\n",
    "            file.write(\"\\t\\t& \\\\multicolumn{4}{c}{\"+\"$\"+metric+\"(\\%)$}\\\\\\\\\\n\")\n",
    "            file.write(\"\\t\\t&\"+\" & \".join([\"\\\\textbf{\"+kb+\"}\" for kb in data[key]])+\"\\\\\\\\\\n\")\n",
    "            file.write(\"\\\\midrule\\n\")\n",
    "            for model in data[key]['Carcinogenesis']:\n",
    "                file.write(\"\\t\\t\"+model+\" & \"+\" & \".join([data[key][kb][model] for kb in data[key]])+\"\\\\\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "defensive-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_shuffle(metric):\n",
    "    data = get_results_shuffle(metric)\n",
    "    with open(f'{metric}_shuffle.txt', 'w') as file:\n",
    "        for key in data:\n",
    "            file.write(\"\\\\begin{tabular}{@{}lccccccc@{}}\\n\")\n",
    "            file.write(\"\\t\\t\\\\toprule\\n\")\n",
    "            file.write(\"\\t\\t& \\\\multicolumn{4}{c}{\"+\"$\"+metric+\"(\\%)$}\\\\\\\\\\n\")\n",
    "            file.write(\"\\t\\t&\"+\" & \".join([\"\\\\textbf{\"+kb+\"}\" for kb in data[key]])+\"\\\\\\\\\\n\")\n",
    "            file.write(\"\\\\midrule\\n\")\n",
    "            for model in data[key]['Carcinogenesis']:\n",
    "                file.write(\"\\t\\t\"+model+\" & \"+\" & \".join([data[key][kb][model] for kb in data[key]])+\"\\\\\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sharp-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results_shuffle('F-measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fourth-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results_shuffle('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
