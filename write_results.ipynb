{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hindu-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "detailed-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_metric(metric):\n",
    "    if metric == 'F-measure':\n",
    "        return 'f1'\n",
    "    if metric == 'Accuracy':\n",
    "        return 'acc'\n",
    "    if metric == 'Runtime':\n",
    "        return 'time'\n",
    "    raise ValueError('Unknown metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "excited-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_add_zero(mean, std):\n",
    "    if len(mean.split('.')[-1]) == 1:\n",
    "        mean += '0'\n",
    "    if len(std.split('.')[-1]) == 1:\n",
    "        std += '0'\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "virgin-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(metric, emb_model=\"TransE\"):\n",
    "    Res = {metric: {'Carcinogenesis': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''},\n",
    "                   'Mutagenesis': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''},\n",
    "                    'Semantic Bible': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''},\n",
    "                    'Vicodi': {'CELOE': '', 'ELTL': '', 'ECII': '', 'EvoLearner': '', 'NCES$_{\\\\text{LSTM}}$': '', 'NCES$_{\\\\text{GRU}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{ST}}$': '', 'NCES$_{\\\\text{ST+GRU}}$': '', 'NCES$_{\\\\text{ST+LSTM}}$': '',\\\n",
    "                                       'NCES$_{\\\\text{GRU+LSTM}}$': '', 'NCES$_{\\\\text{ST+GRU+LSTM}}$': ''}\n",
    "                   }}\n",
    "    for kb in ['carcinogenesis', 'mutagenesis', 'semantic_bible', 'vicodi']:\n",
    "        for model in ['celoe', 'eltl', 'ecii', 'evolearner', 'NCES', 'NCES_Ensemble']:\n",
    "            if model not in ['NCES', 'NCES_Ensemble']:\n",
    "                rename_model = model.upper() if model != 'evolearner' else 'EvoLearner'\n",
    "                with open(f'datasets/{kb}/Results/{rename_model}_avg_results.json') as file:\n",
    "                    results = json.load(file)\n",
    "                mean = str(round(results[metric]['mean'],2)); std = str(round(results[metric]['std'],2))\n",
    "                mean, std = maybe_add_zero(mean, std)\n",
    "                Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] = mean+'$\\pm$'+std\n",
    "            elif model == 'NCES':\n",
    "                path = f'datasets/{kb}/Results/{model}.json'\n",
    "                if emb_model == \"TransE\":\n",
    "                    path = f'datasets/{kb}/Results/{model}_{emb_model}.json'\n",
    "                with open(path) as file:\n",
    "                    results = json.load(file)\n",
    "                new_metric = rename_metric(metric)\n",
    "                for m in results: \n",
    "                    rename_model = 'NCES$_'+'{\\\\text{'+m+'}}$' if m != 'SetTransformer' else 'NCES$_'+'{\\\\text{'+'ST'+'}}$'\n",
    "                    mean = str(round(results[m][new_metric]['mean'][0],2))\n",
    "                    std = str(round(results[m][new_metric]['std'][0],2))\n",
    "                    mean, std = maybe_add_zero(mean, std)\n",
    "                    Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] = mean+'$\\pm$'+std\n",
    "            elif model == 'NCES_Ensemble':\n",
    "                path = f'datasets/{kb}/Results/{model}.json'\n",
    "                if emb_model == \"TransE\":\n",
    "                    path = f'datasets/{kb}/Results/NCES_TransE_Ensemble.json'\n",
    "                with open(path) as file:\n",
    "                    results = json.load(file)\n",
    "                new_metric = rename_metric(metric)\n",
    "                for m in results:\n",
    "                    rename_model = 'NCES$_'+'{\\\\text{'+m+'}}$' if not 'SetTransformer' in m \\\n",
    "                    else 'NCES$_'+'{\\\\text{'+m.replace('SetTransformer', 'ST')+'}}$'\n",
    "                    mean = str(round(results[m][new_metric]['mean'][0],2)); std = str(round(results[m][new_metric]['std'][0],2))\n",
    "                    mean, std = maybe_add_zero(mean, std)\n",
    "                    Res[metric][' '.join(word.capitalize() for word in kb.split('_'))][rename_model] = mean+'$\\pm$'+std\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "induced-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(metric, emb_model=\"TransE\"):\n",
    "    data = get_results(metric, emb_model)\n",
    "    with open(f'{emb_model}_{metric}.txt', 'w') as file:\n",
    "        for key in data:\n",
    "            file.write(\"\\\\begin{tabular}{@{}lccccccc@{}}\\n\")\n",
    "            file.write(\"\\t\\t\\\\toprule\\n\")\n",
    "            file.write(\"\\t\\t& \\\\multicolumn{4}{c}{\"+\"$\"+metric+\"(\\%)$}\\\\\\\\\\n\")\n",
    "            file.write(\"\\t\\t&\"+\" & \".join([\"\\\\textbf{\"+kb+\"}\" for kb in data[key]])+\"\\\\\\\\\\n\")\n",
    "            file.write(\"\\\\midrule\\n\")\n",
    "            for model in data[key]['Carcinogenesis']:\n",
    "                file.write(\"\\t\\t\"+model+\" & \"+\" & \".join([data[key][kb][model] for kb in data[key]])+\"\\\\\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "established-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results('F-measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "severe-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subjective-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results('Runtime')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
