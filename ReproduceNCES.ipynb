{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silent-dimension",
   "metadata": {},
   "source": [
    "## Evaluate NCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equipped-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "kg_path_semb = \"Method/Datasets/semantic_bible/semantic_bible.owl\"\n",
    "\n",
    "kg_path_fam = \"Method/Datasets/family-benchmark/family-benchmark.owl\"\n",
    "\n",
    "kg_path_car = \"Method/Datasets/carcinogenesis/carcinogenesis.owl\"\n",
    "\n",
    "kg_path_mut = \"Method/Datasets/mutagenesis/mutagenesis.owl\"\n",
    "\n",
    "kg_path_vic = \"Method/Datasets/vicodi/vicodi.owl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "awful-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"Method/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposite-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Method.helper_classes.syntax_checker import SyntaxChecker\n",
    "from Method.ontolearn import KnowledgeBase\n",
    "from Method.concept_synthesis.helper_classes import ConceptSynthesizer\n",
    "from Method.base import BaseConceptSynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educated-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reduced-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"learner_name\": \"\", \"emb_model_name\": \"\", 'knowledge_base_path': base_path+f\"Datasets/carcinogenesis/carcinogenesis.owl\",\n",
    "              #\"pretrained_embedding_path\": base_path+f\"Datasets/carcinogenesis/Model_weights/ConEx_GRU.pt\",\n",
    "              \"pretrained_concept_synthesizer\": base_path+f\"Datasets/carcinogenesis/Model_weights/GRU.pt\", \n",
    "              \"path_to_csv_embeddings\": base_path+f\"Embeddings/carcinogenesis/ConEx_entity_embeddings.csv\",\n",
    "              \"learning_rate\": 0.001, \"decay_rate\": 0.0, 'grad_clip_value': 5.0, \n",
    "              \"path_to_triples\": \"\", 'max_num_atom_repeat': 12,\n",
    "              'index_score_upper_bound': 10, 'index_score_lower_bound_rate': 0.8,\n",
    "              'max_length': 32, 'num_workers': 14,\n",
    "              \"embedding_dim\": 20, \"num_entities\": 0,\n",
    "              \"num_relations\": 0, \"num_examples\": 1000, 'drop_prob': 0.1,\n",
    "              \"rnn_n_layers\": 2, 'input_size': 40, 'rnn_n_hidden': 256,\n",
    "              \"proj_dim\": 256, 'num_inds': 32, 'num_heads': 4, 'ln': False, 'num_seeds': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saved-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np, time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "earlier-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(prediction:str, target:str):\n",
    "    def soft(arg1, arg2):\n",
    "        arg1_ = set(BaseConceptSynthesis.decompose(arg1)) - {' '}\n",
    "        arg2_ = set(BaseConceptSynthesis.decompose(arg2)) - {' '}\n",
    "        return 100*float(len(arg1_.intersection(arg2_)))/max(1, len(arg1_.union(arg2_)))\n",
    "\n",
    "    def hard(arg1, arg2):\n",
    "        arg1_ = BaseConceptSynthesis.decompose(arg1)\n",
    "        arg2_ = BaseConceptSynthesis.decompose(arg2)\n",
    "        return 100*float(sum(map(lambda x,y: x==y, arg1_, arg2_)))/max(1, len(arg1_), len(arg2_))\n",
    "    soft_acc = sum(map(soft, prediction, target))/len(target)\n",
    "    hard_acc = sum(map(hard, prediction, target))/len(target)\n",
    "    return soft_acc, hard_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "molecular-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nces(kg_path, kg_kwargs, kg_name, models=['SetTransformer'], verbose=False,  shuffle_examples=False):\n",
    "    print('#'*50)\n",
    "    print('NCES evaluation on {} KG:'.format(kg_name))\n",
    "    print('#'*50)\n",
    "    All_metrics = {m: defaultdict(lambda: defaultdict(list)) for m in models}\n",
    "    with open(f\"Method/Datasets/{kg_name}/Test_data/Data.json\") as file:\n",
    "        data_test = json.load(file)\n",
    "        data_test = list(data_test.items())\n",
    "        \n",
    "    for synthesizer_name in models:\n",
    "        kg = KnowledgeBase(path=kg_path)\n",
    "        kg_kwargs[\"pretrained_concept_synthesizer\"] = \"Method/Datasets/\"+kg_name+\"/Model_weights/\"+synthesizer_name+\".pt\"\n",
    "        kg_kwargs[\"path_to_csv_embeddings\"] = base_path + f\"Embeddings/{kg_name}/ConEx_entity_embeddings.csv\"\n",
    "        synthesizer = ConceptSynthesizer(kg_kwargs)\n",
    "        syntax_checker = SyntaxChecker(kg)\n",
    "        best_pred = ''\n",
    "        for pb_str, pb in data_test:\n",
    "            pos_examples = pb['positive examples']\n",
    "            neg_examples = pb['negative examples']\n",
    "            if shuffle_examples:\n",
    "                random.shuffle(pos_examples)\n",
    "                random.shuffle(neg_examples)\n",
    "            t0 = time.time()\n",
    "            pred_sequence, _ = synthesizer.predict(pos_examples, neg_examples)\n",
    "            try:\n",
    "                best_pred, acc, f1 = syntax_checker.evaluate(pred_sequence[0], pos_examples, neg_examples, verbose=verbose)\n",
    "                print(\"Exact solution: \", pb_str)\n",
    "                duration = time.time()-t0\n",
    "                All_metrics[synthesizer_name]['acc']['values'].append(acc)\n",
    "                All_metrics[synthesizer_name]['prediction']['values'].append(best_pred)\n",
    "                All_metrics[synthesizer_name]['f1']['values'].append(f1)\n",
    "#                str_acc = compute_accuracy(best_pred, pb_str)[1]\n",
    "#                All_metrics[synthesizer_name]['str_acc']['values'].append(str_acc)\n",
    "                \n",
    "            except Exception:\n",
    "                print('Could not understand expression: {}'.format(syntax_checker.correct(pred_sequence[0])))\n",
    "                duration = time.time()-t0\n",
    "                All_metrics[synthesizer_name]['acc']['values'].append(0.0)\n",
    "                All_metrics[synthesizer_name]['prediction']['values'].append('None')\n",
    "                All_metrics[synthesizer_name]['f1']['values'].append(0.0)\n",
    "#                All_metrics[synthesizer_name]['str_acc']['values'].append(0)\n",
    "            All_metrics[synthesizer_name]['time']['values'].append(duration)\n",
    "        \n",
    "        All_metrics[synthesizer_name]['acc']['mean'] = [np.mean(All_metrics[synthesizer_name]['acc']['values'])]\n",
    "        All_metrics[synthesizer_name]['acc']['std'] = [np.std(All_metrics[synthesizer_name]['acc']['values'])]\n",
    "        All_metrics[synthesizer_name]['f1']['mean'] = [np.mean(All_metrics[synthesizer_name]['f1']['values'])]\n",
    "        All_metrics[synthesizer_name]['f1']['std'] = [np.std(All_metrics[synthesizer_name]['f1']['values'])]\n",
    "        All_metrics[synthesizer_name]['time']['mean'] = [np.mean(All_metrics[synthesizer_name]['time']['values'])]\n",
    "        All_metrics[synthesizer_name]['time']['std'] = [np.std(All_metrics[synthesizer_name]['time']['values'])]\n",
    "#        All_metrics[synthesizer_name]['str_acc']['mean'] = [np.mean(All_metrics[synthesizer_name]['str_acc']['values'])]\n",
    "#        All_metrics[synthesizer_name]['str_acc']['std'] = [np.std(All_metrics[synthesizer_name]['str_acc']['values'])]\n",
    "        \n",
    "        print(synthesizer_name+' Speed: {}s +- {} / lp'.format(round(All_metrics[synthesizer_name]['time']['mean'][0], 2),\\\n",
    "                                                               round(All_metrics[synthesizer_name]['time']['std'][0], 2)))\n",
    "        print(synthesizer_name+' Avg Acc: {}% +- {} / lp'.format(round(All_metrics[synthesizer_name]['acc']['mean'][0], 2),\\\n",
    "                                                               round(All_metrics[synthesizer_name]['acc']['std'][0], 2)))\n",
    "        print(synthesizer_name+' Avg F1: {}% +- {} / lp'.format(round(All_metrics[synthesizer_name]['f1']['mean'][0], 2),\\\n",
    "                                                               round(All_metrics[synthesizer_name]['f1']['std'][0], 2)))\n",
    "#        print(synthesizer_name+' Avg Str_Acc: {}% +- {} / lp'.format(round(All_metrics[synthesizer_name]['str_acc']['mean'][0], 2),\\\n",
    "#                                                               round(All_metrics[synthesizer_name]['str_acc']['std'][0], 2)))\n",
    "#        print(\"\\n\")\n",
    "        \n",
    "        with open(\"Method/Datasets/\"+kg_name+\"/Results/NCES.json\", \"w\") as file:\n",
    "            json.dump(All_metrics, file, indent=3, ensure_ascii=False)\n",
    "    return All_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thermal-campaign",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "NCES evaluation on semantic_bible KG:\n",
      "##################################################\n",
      "Exact solution:  City ⊔ EthnicityAttribute ⊔ Group\n",
      "Exact solution:  Man ⊔ PoliticalAttribute\n",
      "Exact solution:  Mountain ⊔ (∃ religiousBeliefOf.⊤)\n",
      "Exact solution:  CognitiveAgent ⊔ FixedHoliday\n",
      "Exact solution:  EvilSupernaturalBeing ⊔ FreshWaterArea ⊔ Mountain\n",
      "Exact solution:  SupernaturalBeing ⊔ (∃ location.⊤)\n",
      "Exact solution:  SupernaturalBeing ⊔ (∃ visitedPlace.⊤)\n",
      "Exact solution:  WaterArea ⊔ (∃ location.⊤)\n",
      "Exact solution:  FreshWaterArea ⊔ Organization\n",
      "Exact solution:  FreshWaterArea ⊔ Man ⊔ StateOrProvince\n",
      "Exact solution:  FreshWaterArea ⊔ Series ⊔ SupernaturalBeing\n",
      "Exact solution:  Human ⊔ ReligiousBeliefSystem\n",
      "Exact solution:  Island ⊔ Organization\n",
      "Exact solution:  FreshWaterArea ⊔ God ⊔ ResidenceGroup\n",
      "Exact solution:  Mountain ⊔ ReligiousOrganization\n",
      "Exact solution:  BeliefGroup ⊔ EthnicityAttribute ⊔ FreshWaterArea\n",
      "Exact solution:  Character ⊔ EthnicityAttribute ⊔ Tribe\n",
      "Exact solution:  Agent ⊔ Nation ⊔ (∃ knows.PoliticalBeliefSystem)\n",
      "Exact solution:  Island ⊔ (∃ location.⊤)\n",
      "Exact solution:  BeliefSystem ⊔ Mountain\n",
      "Exact solution:  Angel ⊔ (∃ location.⊤)\n",
      "Exact solution:  EvilSupernaturalBeing ⊔ (∃ ethnicity.⊤)\n",
      "Exact solution:  ∃ subregionOf.(Nation ⊔ (∃ subregion.FreshWaterArea))\n",
      "Exact solution:  EthnicityAttribute ⊔ SaltWaterArea ⊔ Tribe\n",
      "Exact solution:  FreshWaterArea ⊔ Woman\n",
      "Exact solution:  Organization ⊔ Region\n",
      "SetTransformer Speed: 0.02s +- 0.0 / lp\n",
      "SetTransformer Avg Acc: 26.38% +- 28.67 / lp\n",
      "SetTransformer Avg F1: 34.23% +- 33.54 / lp\n"
     ]
    }
   ],
   "source": [
    "F1_semb = evaluate_nces(kg_path_semb, kwargs, kg_name='semantic_bible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "academic-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_car = evaluate_nces(kg_path_car, kwargs, 'carcinogenesis', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "burning-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_fam = evaluate_nces(kg_path_fam, kwargs, 'family-benchmark', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "velvet-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "NCES evaluation on mutagenesis KG:\n",
      "##################################################\n",
      "SetTransformer Speed: 0.08s +- 0.1 / lp\n",
      "SetTransformer Avg Acc: 57.02% +- 42.28 / lp\n",
      "SetTransformer Avg F1: 61.38% +- 42.21 / lp\n"
     ]
    }
   ],
   "source": [
    "F1_mut = evaluate_nces(kg_path_mut, kwargs, 'mutagenesis', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "welsh-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_vic = evaluate_nces(kg_path_vic, kwargs, 'vicodi', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-printer",
   "metadata": {},
   "source": [
    "## Shuffle positive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_semb_rand = evaluate_nces(kg_path_semb, kwargs_semb, data_test_semb, 'semantic_bible', verbose=False, shuffle_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suffering-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_car_rand = evaluate_nces(kg_path_car, kwargs_car, data_test_car, 'carcinogenesis', verbose=False, shuffle_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thick-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_fam_rand = evaluate_nces(kg_path_fam, kwargs_fam, data_test_fam, 'family-benchmark', verbose=False, shuffle_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wired-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_mut_rand = evaluate_nces(kg_path_mut, kwargs_mut, data_test_mut, 'mutagenesis', verbose=False, shuffle_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "optional-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_car_rand['LSTM'][31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-windsor",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "described-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Method.helper_functions import wilcoxon_statistical_test\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "\n",
    "def celoe_vs_nces_stat_tests():\n",
    "    with open('Method/Datasets/semantic_bible/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('Method/Datasets/semantic_bible/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Semantic Bible KG, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "    \n",
    "    with open('Method/Datasets/family-benchmark/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('Method/Datasets/family-benchmark/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Family Benchmark KG, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "        \n",
    "    with open('Method/Datasets/mutagenesis/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('Method/Datasets/mutagenesis/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Mutagenesis KG, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "        \n",
    "    with open('Method/Datasets/carcinogenesis/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('Method/Datasets/carcinogenesis/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Carcinogenesis KG, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "        \n",
    "    with open('Method/Datasets/vicodi/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('Method/Datasets/vicodi/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Vicodi KG, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "excited-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=45.000, p=0.000\n",
      "Probably different distributions\n",
      "stat=171.000, p=0.000\n",
      "Probably different distributions\n",
      "stat=503.000, p=0.000\n",
      "Probably different distributions\n",
      "On Accuracy of Semantic Bible KG, p_value =  2.778608411556193e-34\n",
      "Probably different distributions\n",
      "\n",
      "On F1 of Semantic Bible KG, p_value =  1.8136514710328702e-33\n",
      "Probably different distributions\n",
      "\n",
      "On RunTime of Semantic Bible KG, p_value =  2.3226326259140437e-31\n",
      "Probably different distributions\n",
      "\n",
      "stat=1.000, p=0.000\n",
      "Probably different distributions\n",
      "stat=21.000, p=0.000\n",
      "Probably different distributions\n",
      "stat=0.000, p=0.000\n",
      "Probably different distributions\n",
      "On Accuracy of Family Benchmark KG, p_value =  1.4579385692155708e-34\n",
      "Probably different distributions\n",
      "\n",
      "On F1 of Family Benchmark KG, p_value =  1.9697375762277328e-34\n",
      "Probably different distributions\n",
      "\n",
      "On RunTime of Family Benchmark KG, p_value =  1.4361464127613523e-34\n",
      "Probably different distributions\n",
      "\n",
      "stat=1.000, p=0.000\n",
      "Probably different distributions\n",
      "stat=231.000, p=0.000\n",
      "Probably different distributions\n",
      "stat=0.000, p=0.000\n",
      "Probably different distributions\n",
      "On Accuracy of Mutagenesis KG, p_value =  1.4317280898844339e-34\n",
      "Probably different distributions\n",
      "\n",
      "On F1 of Mutagenesis KG, p_value =  4.395288354762667e-33\n",
      "Probably different distributions\n",
      "\n",
      "On RunTime of Mutagenesis KG, p_value =  1.4361464127613523e-34\n",
      "Probably different distributions\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'LSTM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0d7ad867131b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mceloe_vs_nces_stat_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-7bb700a127a6>\u001b[0m in \u001b[0;36mceloe_vs_nces_stat_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Method/Datasets/carcinogenesis/Results/NCES.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mnces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mf1_nces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0macc_nces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtime_nces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LSTM'"
     ]
    }
   ],
   "source": [
    "celoe_vs_nces_stat_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-geology",
   "metadata": {},
   "source": [
    "## Training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "plt_data_path = \"Method/Datasets/semantic_bible/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file1:\n",
    "    plt_data1 = json.load(plt_file1)\n",
    "\n",
    "plt_data_path = \"Method/Datasets/family-benchmark/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file2:\n",
    "    plt_data2 = json.load(plt_file2)\n",
    "    \n",
    "    \n",
    "plt_data_path = \"Method/Datasets/carcinogenesis/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file3:\n",
    "    plt_data3 = json.load(plt_file3)\n",
    "\n",
    "plt_data_path = \"Method/Datasets/mutagenesis/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file4:\n",
    "    plt_data4 = json.load(plt_file4)\n",
    "    \n",
    "plt_data_path = \"Method/Datasets/vicodi/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file5:\n",
    "    plt_data5 = json.load(plt_file5)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(plt_data1, plt_data2, name1, name2):\n",
    "\n",
    "    Markers = ['--', ':', '-']\n",
    "    Colors = ['g', 'b', 'm']\n",
    "    i = 0\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,7))\n",
    "    #fig.suptitle('Sharing x per column, y per row')\n",
    "\n",
    "    for crv in plt_data1['loss']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax1.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1\n",
    "    ax1.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax1.set_title(name1)\n",
    "    ax1.set(ylabel='Loss')\n",
    "\n",
    "    for crv in plt_data2['loss']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax2.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1   \n",
    "    ax2.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax2.set_title(name2)\n",
    "\n",
    "    for crv in plt_data1['hard acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax3.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1\n",
    "    ax3.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax3.set(ylabel='Hard Accuracy', xlabel='Epochs')    \n",
    "\n",
    "    for crv in plt_data2['hard acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax4.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1\n",
    "    ax4.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax4.set(xlabel='Epochs')    \n",
    "\n",
    "    for ax in fig.get_axes():\n",
    "        ax.label_outer()\n",
    "    fig.savefig('training-curves'+name1+'_and_'+name2+'.pdf')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(plt_data1, plt_data2, name1='Semantic Bible', name2='Family Benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(plt_data3, plt_data4, name1='Carcinogenesis', name2='Mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-literacy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_acc_curves(plt_data1, plt_data2, plt_data3, plt_data4, plt_data5, name1, name2, name3, name4, name5, mode='hard'):\n",
    "\n",
    "    Markers = ['--', ':', '-']\n",
    "    Colors = ['g', 'b', 'm']\n",
    "    i = 0\n",
    "    fig, ((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, figsize=(30,6), sharey=True)\n",
    "    #fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, figsize=(15,5), sharey=True, sharex=True)\n",
    "    #fig.suptitle('Sharing x per column, y per row')\n",
    "\n",
    "    for crv in plt_data1[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax1.plot(crv, mk, markersize=6, color=c)\n",
    "        i += 1\n",
    "    leg1 = ax1.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg1.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax1.set_title(name1, fontsize=30, fontweight=\"bold\")\n",
    "    ax1.set_xlabel('Epochs', fontsize=25)\n",
    "    ax1.set_ylabel(mode.capitalize()+' Accuracy', fontsize=25)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for crv in plt_data2[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax2.plot(crv, mk, markersize=6, color=c)\n",
    "        i += 1   \n",
    "    leg2 = ax2.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg2.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax2.set_title(name2, fontsize=30, fontweight=\"bold\")\n",
    "    ax2.set_xlabel('Epochs', fontsize=25)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for crv in plt_data3[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax3.plot(crv, mk, markersize=10, color=c)\n",
    "        i += 1\n",
    "    leg3 = ax3.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg3.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax3.set_title(name3, fontsize=30, fontweight=\"bold\")\n",
    "    ax3.set_xlabel('Epochs', fontsize=25)\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for crv in plt_data4[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax4.plot(crv, mk, markersize=10, color=c)\n",
    "        i += 1\n",
    "    leg4 = ax4.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg4.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax4.set_xlabel('Epochs', fontsize=25)\n",
    "    ax4.set_title(name4, fontsize=30, fontweight=\"bold\")\n",
    "    ax4.tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    for crv in plt_data5[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax5.plot(crv, mk, markersize=10, color=c)\n",
    "        i += 1\n",
    "    \n",
    "    leg5 = ax5.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg5.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax5.set_xlabel('Epochs', fontsize=25)\n",
    "    ax5.set_title(name5, fontsize=30, fontweight=\"bold\")\n",
    "    ax5.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for ax in fig.get_axes():\n",
    "        ax.label_outer()\n",
    "    fig.savefig(f'accuracy-curves-all-KGs_{mode}.pdf', bbox_inches='tight')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-block",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name1, name2, name3, name4, name5 = 'Semantic Bible', 'Family Benchmark', 'Carcinogenesis', 'Mutagenesis', 'Vicodi'\n",
    "plot_acc_curves(plt_data1, plt_data2, plt_data3, plt_data4, plt_data5, name1, name2, name3, name4, name5, mode='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-facility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
