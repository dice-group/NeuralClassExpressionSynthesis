{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prescribed-brain",
   "metadata": {},
   "source": [
    "## Evaluate NCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liable-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from utils.syntax_checker import SyntaxChecker\n",
    "from utils.evaluator import Evaluator\n",
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from nces import BaseConceptSynthesis\n",
    "from nces.synthesizer import ConceptSynthesizer\n",
    "from utils.data import Data\n",
    "from owlapy.parser import DLSyntaxParser\n",
    "from dataloader import CSDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loving-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import json\n",
    "import torch, pandas as pd\n",
    "with open(\"settings.json\") as setting:\n",
    "    args = json.load(setting)\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjusted-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medieval-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_pad(arg):\n",
    "    arg_temp = []\n",
    "    for atm in arg:\n",
    "        if atm == 'PAD':\n",
    "            break\n",
    "        arg_temp.append(atm)\n",
    "    return arg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greek-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(prediction, target):\n",
    "    def soft(arg1, arg2):\n",
    "        arg1_ = arg1\n",
    "        arg2_ = arg2\n",
    "        if isinstance(arg1_, str):\n",
    "            arg1_ = set(before_pad(BaseConceptSynthesis.decompose(arg1_)))\n",
    "        else:\n",
    "            arg1_ = set(before_pad(arg1_))\n",
    "        if isinstance(arg2_, str):\n",
    "            arg2_ = set(before_pad(BaseConceptSynthesis.decompose(arg2_)))\n",
    "        else:\n",
    "            arg2_ = set(before_pad(arg2_))\n",
    "        return 100*float(len(arg1_.intersection(arg2_)))/len(arg1_.union(arg2_))\n",
    "\n",
    "    def hard(arg1, arg2):\n",
    "        arg1_ = arg1\n",
    "        arg2_ = arg2\n",
    "        if isinstance(arg1_, str):\n",
    "            arg1_ = before_pad(BaseConceptSynthesis.decompose(arg1_))\n",
    "        else:\n",
    "            arg1_ = before_pad(arg1_)\n",
    "        if isinstance(arg2_, str):\n",
    "            arg2_ = before_pad(BaseConceptSynthesis.decompose(arg2_))\n",
    "        else:\n",
    "            arg2_ = before_pad(arg2_)\n",
    "        return 100*float(sum(map(lambda x,y: x==y, arg1_, arg2_)))/max(len(arg1_), len(arg2_))\n",
    "    soft_acc = sum(map(soft, prediction, target))/len(target)\n",
    "    hard_acc = sum(map(hard, prediction, target))/len(target)\n",
    "    return soft_acc, hard_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comic-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_examples(pos, neg, num_examples):\n",
    "    if min(len(neg),len(pos)) >= num_examples//2:\n",
    "        if len(pos) > len(neg):\n",
    "            num_neg_ex = num_examples//2\n",
    "            num_pos_ex = num_examples-num_neg_ex\n",
    "        else:\n",
    "            num_pos_ex = num_examples//2\n",
    "            num_neg_ex = num_examples-num_pos_ex\n",
    "    elif len(pos) > len(neg):\n",
    "        num_neg_ex = len(neg)\n",
    "        num_pos_ex = num_examples-num_neg_ex\n",
    "    elif len(pos) < len(neg):\n",
    "        num_pos_ex = len(pos)\n",
    "        num_neg_ex = num_examples-num_pos_ex\n",
    "    positive = random.sample(pos, num_pos_ex)\n",
    "    negative = random.sample(neg, num_neg_ex)\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vanilla-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_token(model, idx_array):\n",
    "    return model.inv_vocab[idx_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacterial-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    pos_emb_list = []\n",
    "    neg_emb_list = []\n",
    "    target_tokens_list = []\n",
    "    target_labels = []\n",
    "    for pos_emb, neg_emb, label in batch:\n",
    "        pos_emb_list.append(pos_emb)\n",
    "        neg_emb_list.append(neg_emb)\n",
    "        target_labels.append(label)\n",
    "    pos_emb_list = pad_sequence(pos_emb_list, batch_first=True, padding_value=0)\n",
    "    neg_emb_list = pad_sequence(neg_emb_list, batch_first=True, padding_value=0)\n",
    "    target_labels = pad_sequence(target_labels, batch_first=True, padding_value=-100)\n",
    "    return pos_emb_list, neg_emb_list, target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "known-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(kb, embeddings, kwargs):\n",
    "    data_test_path = f\"datasets/{kb}/Test_data/Data.json\"\n",
    "    with open(data_test_path, \"r\") as file:\n",
    "        data_test = json.load(file)\n",
    "    data_test = list(data_test.items())\n",
    "    test_dataset = CSDataLoader(data_test, embeddings, kwargs)\n",
    "    print(\"Number of learning problems: \", len(test_dataset))\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=kwargs.batch_size, num_workers=kwargs.num_workers, collate_fn=collate_batch, shuffle=False)\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "renewable-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_expressions(model_name, kb, args):\n",
    "    args.knowledge_base_path = \"datasets/\"+f\"{kb}/{kb}.owl\"\n",
    "    embeddings = pd.read_csv(f\"embeddings/{kb}/ConEx_entity_embeddings.csv\").set_index('Unnamed: 0')\n",
    "    dataloader = get_data(kb, embeddings, args)\n",
    "    model = torch.load(f\"datasets/{kb}/Model_weights/{model_name}.pt\", map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    soft_acc, hard_acc = 0.0, 0.0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for x1, x2, labels in tqdm(dataloader):\n",
    "        target_sequence = map_to_token(model, labels)\n",
    "        pred_sequence, _ = model(x1, x2)\n",
    "        preds.append(pred_sequence)\n",
    "        targets.append(target_sequence)\n",
    "        s_acc, h_acc = compute_accuracy(pred_sequence, target_sequence)\n",
    "        soft_acc += s_acc\n",
    "        hard_acc += h_acc\n",
    "    print(f\"Average syntactic accuracy, Soft: {soft_acc/len(dataloader)}%, Hard: {hard_acc/len(dataloader)}%\")\n",
    "    return np.concatenate(preds, 0), np.concatenate(targets, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "japanese-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learning problems:  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average syntactic accuracy, Soft: 85.77870542156258%, Hard: 90.06590514993873%\n",
      "Duration:  4.517004489898682\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "Preds, Targets = predict_class_expressions(\"SetTransformer\", \"carcinogenesis\", args)\n",
    "t1 = time.time()\n",
    "print(\"Duration: \", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "united-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iodine', ' ', '⊔', ' ', '(', '∃', ' ', 'inBond', '.', '(',\n",
       "       'Carbon-17', ' ', '⊔', ' ', 'Fluorine', ')', ')', 'PAD', 'PAD',\n",
       "       'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD',\n",
       "       'PAD', 'PAD', 'PAD', 'PAD'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "applied-irish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iodine', ' ', '⊔', ' ', '(', '∃', ' ', 'inBond', '.', '(',\n",
       "       'Carbon-17', ' ', '⊔', ' ', 'Fluorine', ')', ')', 'PAD', 'PAD',\n",
       "       'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD',\n",
       "       'PAD', 'PAD', 'PAD', 'PAD'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-magnet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "insured-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nces(kb_name, models, args):\n",
    "    print('#'*50)\n",
    "    print('NCES evaluation on {} KB:'.format(kb_name))\n",
    "    print('#'*50)\n",
    "    All_metrics = {m: defaultdict(lambda: defaultdict(list)) for m in models}\n",
    "    print()\n",
    "    kb = KnowledgeBase(path=f\"datasets/{kb_name}/{kb_name}.owl\")\n",
    "    namespace = kb.ontology()._onto.base_iri\n",
    "    print(\"KB namespace: \", namespace)\n",
    "    print()\n",
    "    syntax_checker = SyntaxChecker(kb)\n",
    "    evaluator = Evaluator(kb)\n",
    "    dl_parser = DLSyntaxParser(namespace = namespace)\n",
    "    with open(f\"datasets/{kb_name}/Test_data/Data.json\", \"r\") as file:\n",
    "        data_test = json.load(file)\n",
    "    for model_name in models:\n",
    "        t0 = time.time()\n",
    "        predictions, targets = predict_class_expressions(model_name, kb_name, args)\n",
    "        t1 = time.time()\n",
    "        duration = (t1-t0)/len(predictions)\n",
    "        print()\n",
    "        print(f\"##{model_name}##\")\n",
    "        for i, pb_str in enumerate(targets):\n",
    "            #pos = pb['positive examples']\n",
    "            pb_str = \"\".join(before_pad(pb_str))\n",
    "            examples = data_test[pb_str]\n",
    "            neg_examples = examples['negative examples']\n",
    "            try:\n",
    "                end_idx = np.where(predictions[i] == 'PAD')[0][0] # remove padding token\n",
    "            except IndexError:\n",
    "                end_idx = 1\n",
    "            pred = predictions[i][:end_idx]\n",
    "            #print(\"Before parsing: \", pred.sum())\n",
    "            succeed = False\n",
    "            if (pred=='(').sum() > (pred==')').sum():\n",
    "                for i in range(len(pred))[::-1]:\n",
    "                    try:\n",
    "                        prediction = dl_parser.parse_expression(\"\".join(pred.tolist().insert(i,')')))\n",
    "                        succeed = True\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                if not succeed:\n",
    "                    try:\n",
    "                        pred = syntax_checker.correct(pred.sum())\n",
    "                        pred = list(syntax_checker.get_suggestions(pred))[-1]\n",
    "                        prediction = syntax_checker.get_concept(pred)\n",
    "                    except Exception:\n",
    "                        print(f\"Could not understand expression {pred}\")\n",
    "                        continue\n",
    "            elif (pred==')').sum() > (pred=='(').sum():\n",
    "                for i in range(len(pred)):\n",
    "                    try:\n",
    "                        prediction = dl_parser.parse_expression(\"\".join(pred.tolist().insert(i,'(')))\n",
    "                        succeed = True\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                if not succeed:\n",
    "                    try:\n",
    "                        pred = syntax_checker.correct(pred.sum())\n",
    "                        pred = list(syntax_checker.get_suggestions(pred))[-1]\n",
    "                        prediction = syntax_checker.get_concept(pred)\n",
    "                    except Exception:\n",
    "                        print(f\"Could not understand expression {pred}\")\n",
    "                        continue\n",
    "            else:\n",
    "                try:\n",
    "                    prediction = dl_parser.parse_expression(\"\".join(pred.tolist()))\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        pred = syntax_checker.correct(pred.sum())\n",
    "                        pred = list(syntax_checker.get_suggestions(pred))[-1]\n",
    "                        prediction = syntax_checker.get_concept(pred)\n",
    "                    except Exception:\n",
    "                        print(f\"Could not understand expression {pred}\")\n",
    "                        continue\n",
    "            #duration = time.time()-t0\n",
    "            target_expression = dl_parser.parse_expression(pb_str) # The target class expression\n",
    "            actual_positive_examples = [ind.get_iri().as_str().split(\"/\")[-1] for ind in kb.individuals(target_expression)]\n",
    "            acc, f1 = evaluator.evaluate(prediction, actual_positive_examples, neg_examples)\n",
    "            print(f'Target: {pb_str}, Prediction: {syntax_checker.renderer.render(prediction)}, Acc: {acc}, F1: {f1}')\n",
    "            print()\n",
    "            All_metrics[model_name]['acc']['values'].append(acc)\n",
    "            All_metrics[model_name]['prediction']['values'].append(syntax_checker.renderer.render(prediction))\n",
    "            All_metrics[model_name]['f1']['values'].append(f1)\n",
    "            All_metrics[model_name]['time']['values'].append(duration)\n",
    "            \n",
    "        for metric in All_metrics[model_name]:\n",
    "            if metric != 'prediction':\n",
    "                All_metrics[model_name][metric]['mean'] = [np.mean(All_metrics[model_name][metric]['values'])]\n",
    "                All_metrics[model_name][metric]['std'] = [np.std(All_metrics[model_name][metric]['values'])]\n",
    "        \n",
    "        print(model_name+' Speed: {}s +- {} / lp'.format(round(All_metrics[model_name]['time']['mean'][0], 2),\\\n",
    "                                                               round(All_metrics[model_name]['time']['std'][0], 2)))\n",
    "        print(model_name+' Avg Acc: {}% +- {} / lp'.format(round(All_metrics[model_name]['acc']['mean'][0], 2),\\\n",
    "                                                               round(All_metrics[model_name]['acc']['std'][0], 2)))\n",
    "        print(model_name+' Avg F1: {}% +- {} / lp'.format(round(All_metrics[model_name]['f1']['mean'][0], 2),\\\n",
    "                                                               round(All_metrics[model_name]['f1']['std'][0], 2)))\n",
    "#        print(model_name+' Avg Str_Acc: {}% +- {} / lp'.format(round(All_metrics[model_name]['str_acc']['mean'][0], 2),\\\n",
    "#                                                               round(All_metrics[model_name]['str_acc']['std'][0], 2)))\n",
    "#        print(\"\\n\")\n",
    "        print()\n",
    "        \n",
    "        with open(\"datasets/\"+kb_name+\"/Results/NCES.json\", \"w\") as file:\n",
    "            json.dump(All_metrics, file, indent=3, ensure_ascii=False)\n",
    "    return All_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "perfect-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "christian-female",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#F1_semb = evaluate_nces(kb_path_semb, kwargs, kb_name='semantic_bible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "flush-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_semb['SetTransformer']['f1']['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "still-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "NCES evaluation on carcinogenesis KB:\n",
      "##################################################\n",
      "\n",
      "KB namespace:  http://dl-learner.org/carcinogenesis#\n",
      "\n",
      "Number of learning problems:  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average syntactic accuracy, Soft: 85.77870542156258%, Hard: 90.06590514993873%\n",
      "\n",
      "##SetTransformer##\n",
      "Target: Bond-2 ⊔ Di8, Prediction: Bond-2 ⊔ Di8, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-17 ⊔ Fluorine)), Prediction: Iodine ⊔ (∃ inBond.(Carbon-17 ⊔ Fluorine)), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-15 ⊔ Carbon-26, Prediction: Carbon-15 ⊔ Carbon-26, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-193, Prediction: Carbon-193 ⊔ Nitrogen-33, Acc: 75.0, F1: 85.714\n",
      "\n",
      "Target: Di281 ⊔ Hydrogen-1, Prediction: Di281 ⊔ Hydrogen-1, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Hydrogen-8 ⊔ Oxygen-41)), Prediction: Iodine ⊔ (∃ inBond.(Hydrogen-8 ⊔ Hydrogen-8)), Acc: 96.667, F1: 98.30499999999999\n",
      "\n",
      "Target: Hydrogen-1 ⊔ Phosphorus, Prediction: Hydrogen-1 ⊔ Phosphorus, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Copper-96 ⊔ Fluorine-92)), Prediction: Iodine ⊔ (∃ inBond.(Copper-96 ⊔ Nitrogen-34)), Acc: 19.608, F1: 32.787\n",
      "\n",
      "Target: Di51 ⊔ Krypton-83 ⊔ Non_ar_hetero_6_ring, Prediction: Di51 ⊔ Krypton-83 ⊔ Non_ar_hetero_6_ring, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di66 ⊔ Hydrogen-1, Prediction: Di66 ⊔ Hydrogen-1, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di10 ⊔ Di51, Prediction: Di10 ⊔ Di51, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Calcium-84 ⊔ Phosphorus-62, Prediction: Calcium-84 ⊔ Phosphorus-62, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-26 ⊔ Five_ring, Prediction: Carbon-26 ⊔ Five_ring, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-26 ⊔ Sulfur, Prediction: Carbon-26 ⊔ Sulfur, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Hydrogen-8 ⊔ Sodium, Prediction: Hydrogen-8 ⊔ Sodium, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-14 ⊔ Tellurium)), Prediction: Iodine ⊔ (∃ inBond.(Carbon-14 ⊔ Tin)), Acc: 98.092, F1: 99.03699999999999\n",
      "\n",
      "Target: Hydrogen-2 ⊔ Manganese, Prediction: Barium-115 ⊔ Hydrogen-2, Acc: 50.0, F1: 66.667\n",
      "\n",
      "Target: Carbon-191 ⊔ Compound, Prediction: Carbon-193 ⊔ Compound, Acc: 92.391, F1: 96.045\n",
      "\n",
      "Target: Carbon-10 ⊔ Chlorine-93, Prediction: Carbon-10 ⊔ Carbon-15 ⊔ Carbon-16, Acc: 74.535, F1: 85.41\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.Carbon-21), Prediction: Iodine ⊔ (∃ inBond.(Carbon-21 ⊔ Hydrogen-2)), Acc: 97.872, F1: 98.925\n",
      "\n",
      "Target: Non_ar_6c_ring ⊔ (∃ hasStructure.Di48), Prediction: Non_ar_6c_ring ⊔ (∃ hasStructure.Di48), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Krypton-83 ⊔ Methyl ⊔ Sulfide, Prediction: Krypton-83 ⊔ Methyl ⊔ Sulfide, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-16 ⊔ Hydrogen-1)), Prediction: Iodine ⊔ (∃ inBond.(Carbon-16 ⊔ Oxygen-45)), Acc: 36.923, F1: 53.933\n",
      "\n",
      "Target: Di64 ⊔ Krypton-83 ⊔ Sulfide, Prediction: Di64 ⊔ Krypton-83 ⊔ Sulfide, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di227 ⊔ Di260, Prediction: Di227 ⊔ Di260, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Alkyl_halide ⊔ Ester, Prediction: Alkyl_halide ⊔ Ester, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Ar_halide ⊔ Carbon-14 ⊔ Carbon-15, Prediction: Ar_halide ⊔ Carbon-15 ⊔ Carbon-16, Acc: 52.96999999999999, F1: 69.256\n",
      "\n",
      "Target: Halide ⊔ Krypton-83 ⊔ Non_ar_6c_ring, Prediction: Calcium-84 ⊔ Non_ar_6c_ring, Acc: 39.934, F1: 57.07600000000001\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.Carbon-17), Prediction: Iodine ⊔ (∃ inBond.Carbon-17), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di64 ⊔ Krypton-83 ⊔ Sulfo, Prediction: Di64 ⊔ Krypton-83 ⊔ Sulfo, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Bond-3 ⊔ Ketone, Prediction: Bond-3 ⊔ Nitrogen-31, Acc: 3.8219999999999996, F1: 7.362\n",
      "\n",
      "Target: Carbon-26 ⊔ Oxygen-53, Prediction: Carbon-26 ⊔ Oxygen-53, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Alcohol ⊔ Di227 ⊔ Krypton-83, Prediction: Alcohol ⊔ Di227 ⊔ Krypton-83, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Nitro ⊔ Sulfur-75, Prediction: Nitro ⊔ Sulfur-75, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Chlorine-93 ⊔ Ethoxy, Prediction: Chlorine ⊔ Ethoxy, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Ketone ⊔ Oxygen-49, Prediction: Ketone ⊔ Oxygen-49, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Methoxy ⊔ Ring, Prediction: Methyl ⊔ Ring, Acc: 70.512, F1: 82.706\n",
      "\n",
      "Target: Oxygen-49 ⊔ Sulfo, Prediction: Oxygen-49 ⊔ Oxygen-49, Acc: 80.0, F1: 88.889\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-21 ⊔ Hydrogen-1)), Prediction: Iodine ⊔ (∃ inBond.(Copper-96 ⊔ Sulfur-72)), Acc: 1.982, F1: 3.888\n",
      "\n",
      "Target: Di227 ⊔ Di23 ⊔ Oxygen-41, Prediction: Di227 ⊔ Di23 ⊔ Oxygen-41, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Ester ⊔ Methyl, Prediction: Ester ⊔ Methyl, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Oxygen-42 ⊔ Tin-113)), Prediction: Iodine ⊔ (∃ inBond.(Lead ⊔ Tin-113)), Acc: 38.462, F1: 55.556000000000004\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Nitrogen-499 ⊔ Tellurium)), Prediction: Iodine ⊔ (∃ inBond.(Sulfur-72 ⊔ Tellurium-129)), Acc: 47.059, F1: 64.0\n",
      "\n",
      "Target: Di281 ⊔ Sulfide, Prediction: Di281 ⊔ Sulfide, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Calcium-84 ⊔ Carbon-191, Prediction: Carbon-191 ⊔ Carbon-191, Acc: 95.652, F1: 97.77799999999999\n",
      "\n",
      "Target: Oxygen ⊔ Tin-113, Prediction: Di281 ⊔ Oxygen, Acc: 99.458, F1: 99.72800000000001\n",
      "\n",
      "Target: Carbon-232 ⊔ Di67a, Prediction: Carbon-232 ⊔ Di67a, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di10 ⊔ Nitrogen-32, Prediction: Di10 ⊔ Nitrogen-32, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Calcium-84 ⊔ Nitrogen-33)), Prediction: Iodine ⊔ (∃ inBond.(Calcium ⊔ Nitrogen-33)), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Bromine-94 ⊔ Oxygen-49, Prediction: Chlorine-93 ⊔ Oxygen-49, Acc: 23.474, F1: 38.023\n",
      "\n",
      "Target: Di64 ⊔ Di67a, Prediction: Di48 ⊔ Di67a, Acc: 25.0, F1: 40.0\n",
      "\n",
      "Target: Five_ring ⊔ Krypton-83 ⊔ Non_ar_5c_ring, Prediction: Five_ring ⊔ Krypton-83 ⊔ Ring_size_4, Acc: 67.257, F1: 80.423\n",
      "\n",
      "Target: Nitrogen-38 ⊔ Ring, Prediction: Oxygen-42 ⊔ Ring, Acc: 94.774, F1: 97.317\n",
      "\n",
      "Target: Di260 ⊔ Krypton-83, Prediction: Di260 ⊔ Krypton, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-17 ⊔ Oxygen-51, Prediction: Carbon-17 ⊔ Oxygen-51, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Krypton-83 ⊔ Methyl ⊔ Non_ar_6c_ring, Prediction: Krypton-83 ⊔ Methyl ⊔ Non_ar_6c_ring, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Krypton-83 ⊔ Non_ar_5c_ring ⊔ Sulfo, Prediction: Krypton-83 ⊔ Non_ar_5c_ring ⊔ Sulfo, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di64 ⊔ Sulfo, Prediction: Di64 ⊔ Sulfo, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-15 ⊔ (∃ hasAtom.Copper), Prediction: Carbon-15 ⊔ (∃ hasAtom.Copper), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di260 ⊔ Oxygen-41 ⊔ Ring_size_4, Prediction: Di260 ⊔ Oxygen-41 ⊔ Ring_size_4, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Copper ⊔ Di, Prediction: Di ⊔ Di, Acc: 98.919, F1: 99.457\n",
      "\n",
      "Target: Carbon-193 ⊔ Di227, Prediction: Carbon-193 ⊔ Di227, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-16 ⊔ Carbon-192 ⊔ Carbon-21, Prediction: Carbon-192 ⊔ Carbon-192 ⊔ Carbon-21, Acc: 27.215, F1: 42.786\n",
      "\n",
      "Target: Ester ⊔ Nitrogen-32, Prediction: Ester ⊔ Nitrogen-32, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Arsenic-101 ⊔ Nitrogen-37)), Prediction: Iodine ⊔ (∃ inBond.(Arsenic-101 ⊔ Nitrogen-37)), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Nitrogen ⊔ Oxygen-51, Prediction: Nitrogen ⊔ Oxygen-51, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di66 ⊔ Nitrogen-32, Prediction: Di66 ⊔ Nitrogen-32, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-29 ⊔ Oxygen-53)), Prediction: Iodine ⊔ (∃ inBond.(⊤ ⊔ Copper-96)), Acc: 0.923, F1: 1.828\n",
      "\n",
      "Target: Methyl ⊔ Ring, Prediction: Methyl ⊔ Methyl, Acc: 25.784000000000002, F1: 40.998000000000005\n",
      "\n",
      "Target: Ketone ⊔ Non_ar_hetero_6_ring, Prediction: Ketone ⊔ Non_ar_hetero_6_ring, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Nitrogen-32 ⊔ Sulfide, Prediction: Nitrogen-32 ⊔ Sulfide, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di48 ⊔ Ketone, Prediction: Di48 ⊔ Ketone, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Amino ⊔ Sulfur-76, Prediction: Amino ⊔ Sulfur-76, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Cyanate ⊔ Di23 ⊔ Krypton-83, Prediction: Cyanate ⊔ Di51 ⊔ Krypton-83, Acc: 17.647, F1: 30.0\n",
      "\n",
      "Target: Phosphorus-61, Prediction: Phosphorus-61 ⊔ Phosphorus-61, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-16 ⊔ Carbon-193)), Prediction: Iodine ⊔ (∃ inBond.(Carbon-16 ⊔ Carbon-192)), Acc: 89.024, F1: 94.194\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Nitrogen-37 ⊔ Sulfur-77)), Prediction: Iodine ⊔ (∃ inBond.(Hydrogen-2 ⊔ Sulfur-77)), Acc: 90.90899999999999, F1: 95.238\n",
      "\n",
      "Target: Di64 ⊔ Sulfur-79, Prediction: Di64 ⊔ Sulfur-79, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Manganese ⊔ Phosphorus)), Prediction: Iodine ⊔ (∃ inBond.(Phosphorus ⊔ Phosphorus)), Acc: 99.00999999999999, F1: 99.502\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Nitrogen ⊔ Phosphorus-60)), Prediction: Iodine ⊔ (∃ inBond.(Carbon-15 ⊔ Nitrogen)), Acc: 97.67, F1: 98.821\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Oxygen-51 ⊔ Sulfur-78)), Prediction: Iodine ⊔ (∃ inBond.(Oxygen-51 ⊔ Sulfur-78)), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Chlorine ⊔ Nitrogen-36, Prediction: Chlorine-93 ⊔ Nitrogen-36, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Carbon-232 ⊔ Nitrogen-34, Prediction: Carbon-232 ⊔ Nitrogen-34, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Nitro ⊔ Nitrogen, Prediction: Nitro ⊔ Nitrogen, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Bond-2 ⊔ Sulfur-79, Prediction: Amino ⊔ Sulfur-72, Acc: 0.0, F1: 0.0\n",
      "\n",
      "Target: Carbon-26 ⊔ Di260, Prediction: Carbon-26 ⊔ Di260, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Copper ⊔ Hydrogen-2)), Prediction: Iodine ⊔ (∃ inBond.(Copper-96 ⊔ Nitrogen-499)), Acc: 66.667, F1: 80.0\n",
      "\n",
      "Target: Ar_halide ⊔ Carbon-191 ⊔ Carbon-193, Prediction: Ar_halide ⊔ Carbon-193 ⊔ Carbon-193, Acc: 93.678, F1: 96.736\n",
      "\n",
      "Target: Carbon-10 ⊔ Iodine, Prediction: Carbon-10 ⊔ Di48, Acc: 98.81, F1: 99.401\n",
      "\n",
      "Target: Di66 ⊔ Ring, Prediction: Di66 ⊔ Ring, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Arsenic-101 ⊔ Bromine)), Prediction: Iodine ⊔ (∃ inBond.(Bromine-94 ⊔ Carbon-17)), Acc: 84.483, F1: 91.589\n",
      "\n",
      "Target: Alcohol ⊔ Di ⊔ Oxygen-41, Prediction: Alcohol ⊔ Di ⊔ Oxygen-41, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Phosphorus-62 ⊔ Sulfur-77, Prediction: Phosphorus-62 ⊔ Sulfur-77, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Ring_size_4 ⊔ Sulfur-70, Prediction: Ring_size_4 ⊔ Sulfur-70, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Di64 ⊔ Ring, Prediction: Di64 ⊔ Ring, Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Sulfur-72 ⊔ (∃ inBond.Copper), Prediction: Sulfur-72 ⊔ (∃ inBond.Copper), Acc: 100.0, F1: 100.0\n",
      "\n",
      "Target: Iodine ⊔ (∃ inBond.(Carbon-14 ⊔ Sulfur-75)), Prediction: Iodine ⊔ (∃ inBond.(Carbon-14 ⊔ Carbon-15)), Acc: 98.282, F1: 99.134\n",
      "\n",
      "Target: Alkyl_halide ⊔ Non_ar_6c_ring ⊔ Oxygen-41, Prediction: Alkyl_halide ⊔ Non_ar_6c_ring ⊔ Oxygen-41, Acc: 100.0, F1: 100.0\n",
      "\n",
      "SetTransformer Speed: 0.05s +- 0.0 / lp\n",
      "SetTransformer Avg Acc: 85.41% +- 28.14 / lp\n",
      "SetTransformer Avg F1: 88.45% +- 24.56 / lp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "F1_car = evaluate_nces(\"carcinogenesis\", [\"SetTransformer\"], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-likelihood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incoming-bracket",
   "metadata": {},
   "source": [
    "## Shuffle positive examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-phoenix",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "short-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Method.helper_functions import wilcoxon_statistical_test\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "\n",
    "def celoe_vs_nces_stat_tests():\n",
    "    with open('datasets/semantic_bible/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('datasets/semantic_bible/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Semantic Bible KB, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "    \n",
    "    with open('datasets/family-benchmark/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('datasets/family-benchmark/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Family Benchmark KB, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "        \n",
    "    with open('datasets/mutagenesis/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('datasets/mutagenesis/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Mutagenesis KB, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "        \n",
    "    with open('datasets/carcinogenesis/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('datasets/carcinogenesis/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Carcinogenesis KB, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()\n",
    "        \n",
    "    with open('datasets/vicodi/Results/NCES.json') as file:\n",
    "        nces = json.load(file)\n",
    "    f1_nces = nces['LSTM']['f1']['values']\n",
    "    acc_nces = nces['LSTM']['acc']['values']\n",
    "    time_nces = nces['LSTM']['time']['values']\n",
    "    with open('datasets/vicodi/Results/concept_learning_results_celoe.json') as celoe_file:\n",
    "        celoe = json.load(celoe_file)\n",
    "    f1_celoe = celoe['F-measure']\n",
    "    acc_celoe = celoe['Accuracy']\n",
    "    time_celoe = celoe['Runtime']\n",
    "    _, p1 = wilcoxon_statistical_test(acc_nces, acc_celoe)\n",
    "    _, p2 = wilcoxon_statistical_test(f1_nces, f1_celoe)\n",
    "    _, p3 = wilcoxon_statistical_test(time_nces, time_celoe)\n",
    "    for metric, p in zip(['Accuracy', 'F1', 'RunTime'], [p1,p2,p3]):\n",
    "        print(f'On {metric} of Vicodi KB, p_value = ', p)\n",
    "        if p<=0.05:\n",
    "            print('Probably different distributions')\n",
    "        else:\n",
    "            print('Probably the same distribution')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gross-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#celoe_vs_nces_stat_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-quebec",
   "metadata": {},
   "source": [
    "## Training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "plt_data_path = \"datasets/semantic_bible/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file1:\n",
    "    plt_data1 = json.load(plt_file1)\n",
    "\n",
    "plt_data_path = \"datasets/family-benchmark/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file2:\n",
    "    plt_data2 = json.load(plt_file2)\n",
    "    \n",
    "    \n",
    "plt_data_path = \"datasets/carcinogenesis/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file3:\n",
    "    plt_data3 = json.load(plt_file3)\n",
    "\n",
    "plt_data_path = \"datasets/mutagenesis/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file4:\n",
    "    plt_data4 = json.load(plt_file4)\n",
    "    \n",
    "plt_data_path = \"datasets/vicodi/Plot_data/plot_data.json\"\n",
    "with open(plt_data_path,\"r\") as plt_file5:\n",
    "    plt_data5 = json.load(plt_file5)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(plt_data1, plt_data2, name1, name2):\n",
    "\n",
    "    Markers = ['--', ':', '-']\n",
    "    Colors = ['g', 'b', 'm']\n",
    "    i = 0\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,7))\n",
    "    #fig.suptitle('Sharing x per column, y per row')\n",
    "\n",
    "    for crv in plt_data1['loss']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax1.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1\n",
    "    ax1.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax1.set_title(name1)\n",
    "    ax1.set(ylabel='Loss')\n",
    "\n",
    "    for crv in plt_data2['loss']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax2.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1   \n",
    "    ax2.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax2.set_title(name2)\n",
    "\n",
    "    for crv in plt_data1['hard acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax3.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1\n",
    "    ax3.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax3.set(ylabel='Hard Accuracy', xlabel='Epochs')    \n",
    "\n",
    "    for crv in plt_data2['hard acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax4.plot(crv, mk, markersize=5, color=c)\n",
    "        i += 1\n",
    "    ax4.legend(('GRU', 'LSTM', 'CNN'))\n",
    "    ax4.set(xlabel='Epochs')    \n",
    "\n",
    "    for ax in fig.get_axes():\n",
    "        ax.label_outer()\n",
    "    fig.savefig('training-curves'+name1+'_and_'+name2+'.pdf')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(plt_data1, plt_data2, name1='Semantic Bible', name2='Family Benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(plt_data3, plt_data4, name1='Carcinogenesis', name2='Mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-basement",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_acc_curves(plt_data1, plt_data2, plt_data3, plt_data4, plt_data5, name1, name2, name3, name4, name5, mode='hard'):\n",
    "\n",
    "    Markers = ['--', ':', '-']\n",
    "    Colors = ['g', 'b', 'm']\n",
    "    i = 0\n",
    "    fig, ((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, figsize=(30,6), sharey=True)\n",
    "    #fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, figsize=(15,5), sharey=True, sharex=True)\n",
    "    #fig.suptitle('Sharing x per column, y per row')\n",
    "\n",
    "    for crv in plt_data1[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax1.plot(crv, mk, markersize=6, color=c)\n",
    "        i += 1\n",
    "    leg1 = ax1.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg1.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax1.set_title(name1, fontsize=30, fontweight=\"bold\")\n",
    "    ax1.set_xlabel('Epochs', fontsize=25)\n",
    "    ax1.set_ylabel(mode.capitalize()+' Accuracy', fontsize=25)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for crv in plt_data2[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax2.plot(crv, mk, markersize=6, color=c)\n",
    "        i += 1   \n",
    "    leg2 = ax2.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg2.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax2.set_title(name2, fontsize=30, fontweight=\"bold\")\n",
    "    ax2.set_xlabel('Epochs', fontsize=25)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for crv in plt_data3[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax3.plot(crv, mk, markersize=10, color=c)\n",
    "        i += 1\n",
    "    leg3 = ax3.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg3.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax3.set_title(name3, fontsize=30, fontweight=\"bold\")\n",
    "    ax3.set_xlabel('Epochs', fontsize=25)\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for crv in plt_data4[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax4.plot(crv, mk, markersize=10, color=c)\n",
    "        i += 1\n",
    "    leg4 = ax4.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg4.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax4.set_xlabel('Epochs', fontsize=25)\n",
    "    ax4.set_title(name4, fontsize=30, fontweight=\"bold\")\n",
    "    ax4.tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    for crv in plt_data5[f'{mode} acc']:\n",
    "        mk = Markers[i%3]\n",
    "        c = Colors[i%3]\n",
    "        ax5.plot(crv, mk, markersize=10, color=c)\n",
    "        i += 1\n",
    "    \n",
    "    leg5 = ax5.legend(('GRU', 'LSTM', 'CNN'), prop={'size': 20})\n",
    "    for line in leg5.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "    ax5.set_xlabel('Epochs', fontsize=25)\n",
    "    ax5.set_title(name5, fontsize=30, fontweight=\"bold\")\n",
    "    ax5.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    for ax in fig.get_axes():\n",
    "        ax.label_outer()\n",
    "    fig.savefig(f'accuracy-curves-all-KBs_{mode}.pdf', bbox_inches='tight')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-smooth",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name1, name2, name3, name4, name5 = 'Semantic Bible', 'Family Benchmark', 'Carcinogenesis', 'Mutagenesis', 'Vicodi'\n",
    "plot_acc_curves(plt_data1, plt_data2, plt_data3, plt_data4, plt_data5, name1, name2, name3, name4, name5, mode='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-burlington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
